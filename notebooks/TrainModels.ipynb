{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.initializers.RandomNormal at 0x7fb246121490>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "import sys\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from datasets import CD_Dataset\n",
    "from models import Unet, MimoNet\n",
    "from utility import show_batches, from_categorical, train, crop_receptive, predict_full_image\n",
    "from utility import dice, precision, Pc\n",
    "from datasets import combine_y_w\n",
    "\n",
    "seed = int((time.time()*1e6)%1e6)\n",
    "np.random.seed(seed)\n",
    "keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input name of net: append type e.g. MIMO_expertiment_name\n",
      "\n",
      "MIMO_TEST\n"
     ]
    }
   ],
   "source": [
    "input_patch_size = [500,500] # input patch (expect output to be smaller)\n",
    "input_channels = [3] # RGB\n",
    "output_channels = [2] #cell and bkg\n",
    "NBATCH = 2 # example patch per batch\n",
    "EPCS = 1000 # epochs\n",
    "REG = True # regularization\n",
    "USEW = True # use weights\n",
    "W = 10 # importance of weights\n",
    "JT = True # Just train set means no evaluation during training \n",
    "\n",
    "trained_models_path = '../trained_models'\n",
    "print('\\nInput name of net: append type e.g. MIMO_expertiment_name\\n')\n",
    "NAME_NET = raw_input()\n",
    "if 'MIMO' in NAME_NET :\n",
    "    MIMO = False\n",
    "    UNET = True\n",
    "if 'UNET' in NAME_NET :\n",
    "    MIMO = True\n",
    "    UNET = False\n",
    "\n",
    "NAME_NET = os.path.join(trained_models_path,NAME_NET)\n",
    "if output_channels[0] == 3:\n",
    "    train_y_path = \"train_yc\"\n",
    "    eval_y_path = \"eval_yc\"\n",
    "if output_channels[0] == 2:\n",
    "    train_y_path = \"train_y\"\n",
    "    eval_y_path = \"eval_y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "dataset_path = '../CD_Dataset'\n",
    "dataset = CD_Dataset( path=dataset_path, \n",
    "                     train_y_path=train_y_path,  \n",
    "                     eval_y_path=eval_y_path, \n",
    "                     fit=True, download=True, \n",
    "                     num_classes=output_channels[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input size: [500, 500, 3]\n",
      "output_size: [308, 308, 2]\n"
     ]
    }
   ],
   "source": [
    "# define your model\n",
    "model_input_size = input_patch_size + input_channels\n",
    "if MIMO:\n",
    "    model = MimoNet(model_input_size, classes=output_channels[0], regularized=REG)\n",
    "if UNET:\n",
    "    model = Unet(model_input_size, classes=output_channels[0], regularized=REG)\n",
    "model_output_size = list(model.outputs_shape[0])\n",
    "print(\"input size: {}\\noutput_size: {}\".format(model_input_size,model_output_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== iteration 1/1000 =============\n",
      "Epoch 1/1\n",
      "2/2 [==============================] - 1s 555ms/step - loss: 53.1750 - softmax_categorical_crossentropy: 0.3878 - dice_coef: 0.6990\n",
      "=========== iteration 2/1000 =============\n",
      "Epoch 1/1\n",
      "2/2 [==============================] - 1s 495ms/step - loss: 53.1065 - softmax_categorical_crossentropy: 0.4449 - dice_coef: 0.6894\n",
      "=========== iteration 3/1000 =============\n",
      "Epoch 1/1\n",
      "2/2 [==============================] - 1s 488ms/step - loss: 52.9909 - softmax_categorical_crossentropy: 0.4547 - dice_coef: 0.6822\n",
      "=========== iteration 4/1000 =============\n",
      "Epoch 1/1\n",
      "2/2 [==============================] - 1s 481ms/step - loss: 52.8331 - softmax_categorical_crossentropy: 0.4218 - dice_coef: 0.7076\n",
      "=========== iteration 5/1000 =============\n",
      "Epoch 1/1\n",
      "2/2 [==============================] - 1s 484ms/step - loss: 52.6647 - softmax_categorical_crossentropy: 0.3781 - dice_coef: 0.7116\n",
      "=========== iteration 6/1000 =============\n",
      "Epoch 1/1\n",
      "2/2 [==============================] - 1s 485ms/step - loss: 52.5771 - softmax_categorical_crossentropy: 0.4148 - dice_coef: 0.7141\n",
      "=========== iteration 7/1000 =============\n",
      "Epoch 1/1\n"
     ]
    }
   ],
   "source": [
    "def train(model,dataset, epochs=10, n_batch=10, \n",
    "          use_weights=False, W=20, just_train=True, rotate=False, \n",
    "          name=None,\n",
    "          train_metrics=[],eval_metrics=[] ):\n",
    "\n",
    "    h,w,_ = model.inputs_shape[0]\n",
    "    means = dataset.mean_features()\n",
    "    stds = dataset.std_features()\n",
    "    for i in range(epochs):\n",
    "        print(\"=========== iteration {}/{} =============\".format(i+1,epochs))\n",
    "        if (i+1)%10 == 0 and not(name is None):\n",
    "            print('saving model: {}'.format(name))\n",
    "            model.save_model(name)\n",
    "            y_hat = model.predict(x_train)\n",
    "            xs_c = crop_receptive(x_train,model.outputs_shape[0][:2])\n",
    "            ys_c = crop_receptive(y_train,model.outputs_shape[0][:2])\n",
    "            ys_imgs_c = from_categorical(ys_c)\n",
    "            y_hat_imgs = from_categorical(y_hat)\n",
    "            show_batches([xs_c*stds+means,ys_imgs_c,y_hat_imgs],[\"xs\",\"ys\",\"yhat\"])\n",
    "\n",
    "        x_train,y_train,w_train = dataset.sample_X_Y_W_patch_batch([h,w],n_batch=n_batch,rotate=rotate)\n",
    "        if use_weights:\n",
    "            y_train = combine_y_w(y_train,w_train*W)    \n",
    "        train_history = model.fit(x_train,y_train)\n",
    "        train_metric = train_history.history.values()\n",
    "        \n",
    "        if not just_train:\n",
    "            x_eval1,y_eval1,w_eval1 = dataset.sample_X_Y_W_patch_batch([h,w],n_batch=n_batch,train=False)\n",
    "            x_eval2,y_eval2,w_eval2 = dataset.sample_X_Y_W_patch_batch([h,w],n_batch=n_batch,train=False)\n",
    "\n",
    "            x_eval = np.concatenate( (x_eval1,x_eval2), axis=0 )\n",
    "            y_eval = np.concatenate( (y_eval1,y_eval2), axis=0 )\n",
    "            w_eval = np.concatenate( (w_eval1,w_eval2), axis=0 )\n",
    "\n",
    "            eval_history = model.evaluate(x_eval,y_eval)\n",
    "            eval_metric = eval_history\n",
    "\n",
    "            eval_metrics += [eval_metric]\n",
    "        train_metrics += [train_metric]\n",
    "    if not(name is None):\n",
    "        print('saving model: {}'.format(name))\n",
    "        model.save_model(name)\n",
    "        eval_histo = np.array(eval_metrics)\n",
    "        train_histo = np.array(train_metrics)\n",
    "        train_histo.dump(name+'_train_histo.pkl')\n",
    "        eval_histo.dump(name+'_eval_histo.pkl')\n",
    "    return eval_metrics, train_metrics\n",
    "\n",
    "histo = train(model,dataset,n_batch=NBATCH,epochs=EPCS,just_train=JT,use_weights=USEW, W=W, name=NAME_NET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p27)",
   "language": "python",
   "name": "conda_tensorflow_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
